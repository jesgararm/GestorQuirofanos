\apendice{Documentación técnica de programación}

\section{Introducción}

Para realizar un correcto \textbf{análisis} del desarrollo de este proyecto, son necesarias algunas consideraciones respecto al entorno de desarrollo, las dependencias funcionales y las opciones de integración y despliegue.

\section{Estructura de directorios}

Dentro del repositorio, podemos encontrar:
\begin{itemize}
    \item \textit{./}: Directorio raíz. Contiene la licencia, el logo, el fichero \textit{léeme} para la página principal de GitHub, la estructura de base datos para su importación y todos los paquetes y directorios que conforman el proyecto.
    \item \textit{./API}:  Sistema que contiene la API con los servicios de Predicción y Planificación quirúrgica.
    \item ./\textit{API}/\textit{uploads}: Directorio de almacenamiento temporal que recoge los archivos enviados por los usuarios antes de ser procesados y eliminados.
    \item \textit{./API/src}: Código fuente de la API.
    \item \textit{./API/src/scheduling}: Contiene las clases y paquetes encargados de la tarea de planificación, así como el archivo Dockerfile para ser encapsulado.
    \item \textit{./API/src/scheduling/Optimizacion}: Directorio con clases y paquetes con los algoritmos de optimización y planificación.
    \item \textit{./API/src/scheduling/Optimizacion/Genético}: Clases para el algoritmo genético.
    \item \textit{./API/src/scheduling/Optimizacion/Heurísticas}: Clases para las heurísticas de planificación.
    \item \textit{./API/src/predictions}: Directorio con clases encargadas de cargar el modelo de ML predictivo.
    \item \textit{./API/src/common}: Clases comunes a todos los paquetes. Encargados fundamentalmente de tareas de procesamiento de datos y ficheros.
    \item \textit{./APP-WEB}: Contiene el Dockerfile y el código fuente de la interfaz web.
    \item \textit{./APP-WEB/src}: Código fuente de la aplicación.
    \item \textit{./APP-WEB/src/admin}: Contiene las rutas a las funcionalidades del usuario administrador.
    \item \textit{./APP-WEB/src/auth}: Contiene las rutas para la funcionalidad de autenticación en sistema.
    \item \textit{./APP-WEB/src/forms}: Contiene los formularios en formato Flask WTF para incluirlos en las plantillas HTML.
    \item \textit{./APP-WEB/src/models}: Clases y paquetes que encapsulan el modelo de comunicación con la base de datos.
    \item \textit{./APP-WEB/src/models/entities}: Contiene las clases que representan las entidades persistentes de la BBDD.
    \item \textit{./APP-WEB/src/public}: Contiene las rutas para todas las funcionalidades disponibles para los usuarios.
    \item \textit{./APP-WEB/src/static}: Contiene los archivos de formato de estilos, imágenes... a incluir en las plantillas estáticas.
    \item \textit{./APP-WEB/src/templates}: Contiene las plantillas en lenguaje de marcado HTML, que se corresponden con la \textit{Vista} del usuario.
    \item \textit{./APP-WEB/src/templates/admin}: Plantillas dedicadas a la vista del administrador.
    \item \textit{./APP-WEB/src/templates/user}: Plantillas para la vista de cualquier usuario.
    \item \textit{./APP-WEB/src/templates/auth}: Plantillas para la función de identificación en el sistema.
    \item \textit{./Documentación}: Se incluye la memoria, anexos y diagramas.
    \item \textit{./Documentación/img}: Ruta de las imágenes que se encuentran en el entregable.
    \item \textit{./Documentación/tex}: Capítulos y apartados de memoria y anexos, en formato latex.
    \item \textit{./Documentación/UML}: Directorio con diagramas de casos de uso, interacción y secuencia.
    \item \textit{./Experimentación}: Colección de Jupyter Notebooks que ilustran el proceso de investigación llevado a cabo hasta obtener la solución propuesta.
    \item \textit{./Experimentación/Datos}: Colección de conjuntos de datos anonimizados para labores de ML.
    \item \textit{./Experimentación/Modelos}: Análisis, diseño y explotación de modelos predictivos de aprendizaje supervisado.
    \item \textit{./Experimentación/Optimización}: Análisis, diseño y explotación de algoritmos de planificación paralela.
    \item \textit{./Experimentación/Preprocesado:} Herramientas de preprocesamiento de datos a partir de los listados originales.
    \item \textit{./Preprocesado}: Clase con utilidades para estandarizar y homogeneizar las fuentes de datos en un formato compatible con los modelos propuestos.
\end{itemize}


\section{Manual del programador}

En este apartado desglosaremos la estructura del sistema de forma que sirva de referencia para futuros desarrolladores para su análisis y contribución al proyecto.

Para ello, haremos referencia al \textbf{entorno y dependencias} necesarias para el desarrollo, la obtención del \textbf{código fuente}, su \textbf{ejecución} y posterior \textbf{exportación}.

\subsection{Entorno de desarrollo}

Para comenzar con la \textit{explotación} del sistema, se recomiendan las siguientes herramientas y dependencias:

\subsubsection{Python 3.8-3.11}

En nuestro caso hemos usado la última versión ofrecida por \textbf{Anaconda}, pues ya incluye gran parte de las librerías necesarias para las tareas de análisis y minería de datos, cuya guía de instalación se encuentra disponible \href{https://docs.anaconda.com/free/anaconda/install/index.html}{aquí}.

\subsubsection{Virtualenv}

Incluido en la mayor parte de distribuciones de Python (\textit{incluido en Anaconda}). Permite trabajar con entornos \textit{virtuales}, de gran utilidad cuando construimos subsistemas exportables y queremos \textbf{acotar} las librerías necesarias para cada entorno.

En caso de no estar disponible, puede instalarse con el comando pip:
\texttt{\textit{pip -U install virtualenv}}

\subsubsection{IDEs}

Se recomienda la instalación de una interfaz de apoyo al desarrollo compatible con Python.
Recomendamos la instalación de \href{https://code.visualstudio.com/download}{Visual Studio Code}, la \href{https://marketplace.visualstudio.com/items?itemName=ms-python.python}{extensión de Python} y el \href{https://marketplace.visualstudio.com/items?itemName=HansUXdev.bootstrap5-snippets}{plugin de plantillas Bootstrap 5}.

Por otra parte, el IDE Pycharm, en su versión \textbf{Professional}, incluye soporte y apoyo al desarrollo web con Flask, añadiendo integración con HTML, JS y SQL y está disponible de forma \textit{gratuita} para la comunidad educativa y es accesible desde \href{https://www.jetbrains.com/es-es/pycharm/download/#section=windows}{aquí}.

Sin embargo, pese a haber explorado ambos IDE para la confección del código fuente, la totalidad del proyecto puede ser desarrollado desde cualquiera de ellos, sin necesidad de combinar su uso.

\subsubsection{Git}

Necesario para hacer uso del \href{https://github.com/jesgararm/GestorQuirofanos}{repositorio}. Nuestro repositorio es público, recomendándose realizar un \textit{fork} del mismo en una cuenta privada de \textit{GitHub} y trabajar desde una copia privada del mismo en nuestro entorno:

\imagen{fork}{Vista del repositorio y función de fork}

Por otro lado, es recomendable disponer de \textit{git} instalado en el computador principal, para poder acceder al código fuente y poder realizar modificaciones con cambios persistentes.

Recomendamos para tal índole la instalación de la suite \href{https://docs.github.com/en/desktop/installing-and-configuring-github-desktop/installing-and-authenticating-to-github-desktop/installing-github-desktop}{Github Desktop}, pues permite desde un interfaz sencillo y comprensible realizar la clonación del repositorio en un equipo local y manejar las modificaciones y las \textit{ramas} de trabajo sin necesidad de conocer los parámetros y funcionalidades \textit{git} desde la línea de comandos.

\subsubsection{Sistema Gestor de Bases de Datos (SGBD)}

Es recomendable, para realizar pruebas y comprender el diseño de datos, contar con un sistema gestor de base de datos \textbf{compatible con MySQL e InnoDB}.

Recomendamos la instalación de \href{https://www.apachefriends.org/es/index.html}{XAMPP}, que es un entorno de desarrollo PHP que incluye el SGBD phpmyadmin. Desde ese entorno hemos diseñado y realizado las pruebas locales del sistema, previa a su exportación del esquema en fichero sql.

\subsubsection{Docker}

Dado que usaremos contenedores para encapsular la lógica del sistema y, posteriormente, desplegarlos para su funcionamiento desde cualquier computador, debemos tener el \textit{daemon} Docker instalado en nuestro sistema.

Al igual que con \textit{git}, recomendamos la instalación del GUI oficial de Docker, \href{https://docs.docker.com/desktop/install/windows-install/}{Docker Desktop}. 


\subsection{Obtención del código fuente}

Una vez instalado \textit{\textbf{Github Desktop}} y realizado un \textit{fork} del repositorio, podemos obtener su contenido desde el propio interfaz: \texttt{File > Clone Repository}

\imagen{githubdesktop}{Clonar Repositorio con Github Desktop}

Por otro lado, desde \textit{Git Bash}, abriendo la terminal en el directorio local donde deseemos obtener la copia del código fuente, bastará con ejecutar el siguiente comando:

\texttt{git clone https://github.com/jesgararm/GestorQuirofanos.git}

\subsection{Importación del proyecto e instalación de dependencias}

Dado que Python es un lenguaje \textit{interpretado}, no es necesaria su compilación, por lo que los IDEs no requieren de proyectos con dependencias funcionales preestablecidas (\textit{al contrario que otros desarrollados en lenguajes compilados, como Java}).

Para empezar a trabajar en el repositorio clonado, basta con añadir al entorno de trabajo de nuestro IDE la localización local del repositorio. Por ejemplo, desde VS Code:
\texttt{File > Add Folder to Workspace}

\imagen{vscodefolderpng}{Agregar repositorio local al entorno de trabajo de Visual Studio Code}

\subsubsection{Entornos virtuales e instalación de librerías y dependencias}

Python y la librería \textit{virtualenv} nos permiten trabajar con \textbf{entornos virtuales}. Esto nos permite instalar y trabajar con entornos de python \textbf{aislados}, cada uno con sus librerías y dependencias independientes del paquete que tengamos instalados en la raíz de nuestro sistema.

Cabe destacar que, una vez instalado y activado un entorno, todas las dependencias agregadas al mismo serán \textit{exclusivas} de éste y no serán duplicadas en el entorno principal. Del mismo modo, las librerías principales no serán accesibles desde el nuevo entorno, debiendo configurarlo y definirlo desde 0 tras su activación.

Recomendamos la creación de \textbf{dos entornos virtuales}, uno para cada subsistema. Para ello, nos situaremos en el directorio \textit{./API} o \textit{./APP-WEB} y ejecutaremos el comando:

\texttt{virtualenv [nombreentorno]}

Una vez realizado, pasaremos a su activación, ejecutando el script correspondiente (desde Windows):

\texttt{./[nombreentorno]/Scripts/activate}

Desde allí, podemos instalar las librerías y dependencias. Se incluye un fichero \textit{requirements.txt} con las librerías en la raíz de ambos directorios (API y APP-WEB), por lo que su instalación es sencilla con el comando pip:

\texttt{pip install -r requirements.txt}

Para salir del entorno y pasar al principal (PATH de nuestro S.O), ejecutaremos \texttt{deactivate}.

\imagen{venv}{Activación y desactivación de entorno virtual}

\section{Compilación, instalación y ejecución del proyecto}

El proyecto está elaborado principalmente en python, lenguaje \textit{interpretado}, por lo que tan sólo se requiere un intérprete de python con las librerías necesarias para su ejecución, no siendo necesaria su \textbf{compilación}.

Por otro lado, se ofrece un \textit{despliegue} en Amazon Web Services desde al que acceder al mismo. El enlace a la aplicación web se encuentra actualizado en la sección \href{https://github.com/jesgararm/GestorQuirofanos#readme}{README} del repositorio:

\imagen{readme}{Localización de enlace al despliegue de la aplicación en GitHub}

Por tanto, en este apartado se describen los pasos a seguir para \textit{desplegar} la aplicación en AWS.

\subsection{Primer paso: Configuración de base de datos}

\subsubsection{Creación e inicio de Base de Datos en AWS}

Accederemos, tras iniciar sesión, a \href{https://aws.amazon.com/es/rds/}{Amazon RDS}, que es el servicio de base de datos relacionales. Una vez allí, crearemos una nueva base de datos (\textit{existe un enlace directo a la funcionalidad desde el panel principal}), seleccionando MySQL y configurando los datos de usuario maestro según el contenido del fichero \texttt{./APP-WEB/src/config.py}, que en nuestro caso se corresponden con \textit{root} como nombre de usuario y \textit{gestorquirofanos} como contraseña.


\imagen{rdscreate}{Configuración de usuario maestro en base de datos RDS}

El resto de los parámetros pueden mantenerse inalterables hasta finalizar el formulario.

\subsubsection{Obtención de parámetros de conexión e importación del esquema}

Tras la creación, desde el panel \textit{Bases de Datos} de la barra de herramientas en RDS, obtendremos un listado de todas las BBDD relacionales creadas.

Al seleccionar la recién creada, acudiremos a un panel que muestra las características de la misma. Desde allí, en el apartado \texttt{Conectividad y Seguridad > Punto de enlace y puerto}, obtendremos los parámetros de conexión para la gestión de la base de datos desde un SGBD.

\imagen{panelrds}{Panel de configuración y características de BD en Amazon RDS}

Tras su obtención, nos conectaremos a la misma, creando una nueva conexión y añadiendo los valores de enlace y puerto, así como el usuario y contraseña.

\imagen{ejemploMySQLWorkbench}{Ejemplo de conexión a BD RDS usando MySQL Workbench}

Tras establecerse la conexión, deberemos crear un \textit{nuevo schema}, denominado \textit{gestor\_quirófanos} y, tras seleccionarlo, ejecutar el script \texttt{./schema\_gestor\_quirofanos.sql}.

Tras la ejecución del script, se crearán las tablas y las dependencias funcionales entre ellas, así como habrá algunos usuarios, predicciones y planificaciones de prueba.

\imagen{schemaGestorQuirofanos}{Vista de script y resultado de su ejecución en conexión a BD RDS}

\subsubsection{Actualización de parámetros de conexión a BD}

Es en el fichero \texttt{./APP-WEB/src/config.py} donde se especifican los parámetros de conexión de nuestro interfaz con la base de datos.

Allí encontramos dos definiciones en la clase \textbf{\textit{DevelopmentConfig}}, una para la conexión con la BD local y otra para la remota.

Para configurarlo, bastará con dejar comentada la porción de código que no nos interesa y actualizar los datos de conexión en la variable \textit{MYSQL\_HOST}.

\imagen{config}{Código fuente con las rutas de conexión con el esquema \textit{gestor\_quirófanos} en la base de datos}

\subsection{Segundo paso: Creación de contenedor API}

Contando con la existencia del \textit{daemon} Docker ejecutándose (basta con iniciar el interfaz Docker Desktop en segundo plano) y los ficheros \textit{Dockerfile}, podremos crear con facilidad desde línea de comandos estos contenedores.

Debemos crear dos contenedores, uno en cada subsistema, a partir del contenido del directorio \texttt{API} y \texttt{APP-WEB}.

Dado que debemos contar con la \textbf{información de conexión de la API} de cara a ejecutar el interfaz web, debemos proceder con estos pasos de forma secuencial para cada uno de ambos subsistemas.

Por ello, nos situamos en \texttt{./API} y ejecutamos \texttt{docker build -t [nombreapi] .}

Tras la ejecución \textit{automática} de los pasos detallados en \textit{Dockerfile}, se creará una \textit{imagen} del contenedor, que podremos ejecutar o desplegar en un servidor.

\imagen{dockerAPI}{Creación de contenedor para la API desde línea de comandos}

\subsection{Tercer paso: Desplegar la API}

\subsubsection{Publicación en Amazon ECR}

Para desplegar la API debemos, en primer lugar, almacenar el docker en un \textbf{repositorio} Amazon, haciendo uso de la herramienta \href{https://aws.amazon.com/es/ecr/}{Elastic Container Registry}.

Debemos crear un nuevo repositorio (\textit{enlace en la ventana principal}), seleccionar la visibilidad pública y añadir un nombre que \textbf{coincida} con el del contenedor, no siendo necesarias más modificaciones.

\imagen{formECR}{Formulario de creación de un repositorio Amazon ECR}

Para el siguiente paso, es conveniente tener instalado el gestor en línea de comandos \href{https://docs.aws.amazon.com/es_es/cli/latest/userguide/getting-started-install.html}{AWS CLI}.

Una vez instalada esta utilidad, seleccionaremos nuestro repositorio y marcaremos la opción \texttt{Mostrar claves de envío}, abriéndose una ventana con los pasos a seguir para publicar la imagen del contenedor en nuestro repositorio:

\imagen{postECR}{Ejemplo de claves de envío Amazon ECR}

Si seguimos los pasos detallados en la ventana, conseguiremos publicar la imagen del contenedor en nuestro repositorio:

\imagen{pushECR}{Ejecución satisfactoria de la subida de un contenedor a repositorio Amazon ECR}

\subsubsection{Despliegue en Amazon ECS}

Una vez almacenado, podremos ejecutar el contenedor en un servidor proporcionado por AWS, mediante la función \textit{Elastic Container Services}.

Deberemos crear (\textit{si no disponemos aún}) un clúster, encargado de ejecutar contenedores a modo de \textbf{servicios y tareas}:

\imagen{vistaClusterTFG}{Visualización de panel de de configuración de nuestro cluster \textbf{ubutfgcluster}}


Crearemos un nuevo \textit{servicio} mediante la opción habilitada para ello en nuestro panel. Podremos dejar todas las opciones marcadas \textbf{por defecto}, debiendo añadir una \textit{definición de tarea} con la URI de la imagen en ECR y el puerto 4000, guardándola con el nombre de \textit{API-TFG}:

\imagen{defTarea}{Definición de familia de tareas API-TFG, añadiendo enlace a la imagen del contenedor en ECR}

Tras la definición de la tarea, volveremos al formulario anterior, donde registraremos el servicio \textit{gestorquirofanosapi}, ligándolo a la familia de tareas API-TFG:

\imagen{defServicio}{Definición de servicio \textbf{\textit{gestorquirofanosapi}} en el cluster}

El servicio arrancará unos instantes después, permitiendo obtener la dirección de acceso a la API en ejecución y pasar al encapsulamiento y despliegue del interfaz.

\subsection{Cuarto Paso: Configuración de rutas de acceso a la API}

Tras arrancar el servicio, deberemos obtener la \textbf{dirección pública} de la tarea en ejecución. Para ello: \texttt{Selección de servicio > Tareas > Tarea > Condiguración > IP pública}

\imagen{tareaIP}{Localización de URL del despliegue de la API}

Una vez allí, en los métodos localizados en \texttt{./APP-WEB/src/public/routes.py} donde se especifique la conexión con la API  (\textit{upload y uploadSched}), comentaremos la línea de conexión con el servidor local y añadiremos:

\begin{itemize}
    \item \textit{http://[url]:4000/predict}: Para las funciones de predicción.
    \item \textit{http://[url]:4000/schedule}: Para las funciones de planificación.
\end{itemize}

\imagen{modRoute}{Modificación de las rutas}

\subsection{Quinto Paso: Encapsulamiento en Docker y despliegue}

De forma similar al paso anterior, nos situamos en línea de comandos en el directorio \texttt{./APP-WEB} y ejecutamos:

\texttt{docker build -t gestorquirofanosapp .}

Tras su ejecución, crearemos un nuevo repositorio, de nombre \textit{gestorquirofanosapp}, siguiendo los comandos del \textbf{tercer paso} (\textit{aunque sustituyendo el nombre gestorquirofanosapi por gestorquirofanosapp}):

\imagen{postECR2}{Comandos de envío del contenedor \textbf{\textit{gestorquirofanosapp}} al nuevo repositorio ECR}

Por último, deberemos definir una nueva tarea (que hemos nombrado como \textit{APP-TFG}) y seleccionarla como base de un nuevo servicio en el clúster, que llamaremos \textit{gestorquirofanosapp}, estableciendo el puerto 5000.

Una vez iniciado el servicio, accederemos a la tarea y a su dirección, siendo ésta la base para la construcción de la \textbf{URL del despliegue de nuestra aplicación web}:

\textit{URL = http://[url-tarea]:5000}

\imagen{urlAPP}{Obtención de la dirección pública del despligue de la APP}

\subsection{Sexto Paso: Comprobación del despliegue}

Accedemos a la URL y comprobamos su funcionamiento:

\imagen{despliegueAPP}{Comprobación del correcto despliegue del sistema en AWS}

\section{Pruebas del sistema}

Podemos distinguir varias etapas en nuestro proceso de pruebas del sistema: 

\begin{itemize}
    \item Pruebas de los modelos de aprendizaje supervisado.
    \item Pruebas de los algoritmos de optimización.
    \item Pruebas de sistema en la API.
    \item Pruebas de sistema e integración en aplicación web.
\end{itemize}

\subsection{Pruebas de los modelos de aprendizaje supervisado y de algoritmos de optimización}

En este tipo de pruebas se analizó el \textbf{rendimiento} de los distintos modelos, incluyendo representaciones gráficas de la adaptación y ajuste de los mismos respecto a los valores \textit{reales}.

Aprovechando la \textbf{versatilidad} de python como lenguaje \textit{interpretado} y la existencia de los cuadernos Jupyter, pudimos documentar todo el proceso de análisis y pruebas dentro de los mismos.

\imagen{KNNPerf}{Ejemplo de gráfico de rendimiento (\textit{KNN}) disponible en los Jupyter Notebooks}

Todos los cuadernos, con las celdas de código ejecutadas, pueden encontrarse en: \texttt{./Experimentación/Modelos}.

Por otro lado y, siguiendo un enfoque similar, se documentaron las pruebas y el análisis del rendimiento de los algoritmos de optimización (\textit{genético, heurísticas y PSO}) en Jupyter. Accesibles en: 
\texttt{./Experimentación/Optimizacion}

\subsection{Pruebas en la API}

Una vez integrados los modelos en una API, procedimos a su \textit{testeo} mediante un enfoque de \textbf{caja negra}.

Para ello, nos valimos del software \href{https://www.postman.com/}{Postman}, que es una API capaz de conectarse y explotar otras APIs (\textit{realizar peticiones GET ,POST ,UPDATE...}) y es ampliamente usada en la comunidad de desarrolladores para la ejecución de pruebas de sistema sobre otras interfaces de programación de aplicaciones.

Se siguieron las recomendaciones habituales para el diseño de los casos de prueba:

\begin{itemize}
    \item Un caso de prueba por cada requerimiento.
    \item Empleo de valores límites en los parámetros del formulario.
    \item Prueba de valores válidos e inválidos.
\end{itemize}

\imagen{postman}{Ejemplo de \textit{request} y \textit{response} durante las pruebas de sistema en la API}

Una vez publicada y en funcionamiento dentro del servicio AWS ECS, se actualizaron las direcciones y puerto, repitiéndose la ejecución de los casos de prueba.

\subsection{Pruebas en aplicación web}

De nuevo, mediante un enfoque de \textbf{caja negra}, se ampliaron los casos de prueba añadiendo los requisitos funcionales de \textit{gestión de usuario} y no funcionales de la \textit{interfaz}.

Las pruebas se realizaron \textbf{manualmente}, dado que el número de casos de prueba y funcionalidades a testear no requirieron de automatización.

Como hecho diferenciador, se añadieron \textbf{pruebas de usuario} sobre la interfaz, solicitando y otorgando acceso a la aplicación a tres perfiles de usuario \textit{diferentes}: cirujano, enfermero y administrativo.
Sin supervisión directa, exploraron el interfaz y entregaron, en una reunión posterior, su punto de vista y recomendaciones de cara a la adecuación del software a sus requisitos.

