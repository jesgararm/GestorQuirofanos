\capitulo{3}{Conceptos teóricos}

En el siguiente proyecto se hace uso de algunas técnicas de \textbf{aprendizaje automático} y \textbf{optimización} que conviene describir de cara a la mejor comprensión de los pasos seguidos hacia su resolución.

Tal y como se ha comentado, se parte de un \textbf{modelo predictivo}, basado en técnicas de \textit{aprendizaje supervisado} para estimar la duración de una intervención quirúrgica en base a los datos introducidos por el usuario.

Posteriormente, partiremos de la salida del modelo para realizar una \textbf{programación} de tipo \textit{parallel scheduling}\footnote{Programar n trabajos en m máquinas paralelas\cite{Xing2000ParallelJobs}, se asemeja a programar n intervenciones en m quirófanos simultáneos}, usando una aproximación con restricciones que definen un problema \textbf{MIP}\footnote{\textit{Mixed Integer Programming}: Problemas de programación dinámica en la que algunas de sus variables deben ser enteras.\cite{RichardsMixed-integerControl}} \cite{Lin2020AScheduling} y resultan en un problema \textit{NP-Hard}.



\section{Aprendizaje Supervisado}

El aprendizaje supervisado es un enfoque de inteligencia altificial en el cual un algoritmo es entrenado a partir de datos de entrada para producir una \textbf{determinada salida}. 

Este modelo es entrenado hasta que es capaz de detectar los patrones y relaciones entre los datos de entrada y las \textit{etiquetas} de salida, de forma que pueda otorgar resultados precisos cuando se le presenten datos \textit{nuevos}\cite{PeterssonSupervisedLearning}.

Reflejaremos en las siguientes subsecciones los diferentes algoritmos empleados para el proceso predictivo.

\subsection{Regresión Lineal}

Existen diferentes tipos de algoritmos de regresión, siendo cada uno de ellos el más adecuado en función del problema a resolver.

El mecanismo de regresión lineal más \textbf{simple} es aquel definido para dibujar una línea a través de un grafo que muestra dependencia lineal entre ambas variables y su ecuación es\cite{Belyadi2021SupervisedLearning}:
\begin{equation}
    y=mx+b
\end{equation}
Donde \textit{m} representa a la pendiente de la recta, \textit{b} a la ordenada en el origen, \textit{y} es la variable dependiente (característica de salida) y \textit{x} la independiente (característica de entrada).

Para modelos de regresión lineal múltiple, que es el que manejaremos en nuestro trabajo, usamos la ecuación siguiente\cite{Belyadi2021SupervisedLearning}: 
\begin{equation}
    y = m_{1} x_{1} + m_{2} x_{2} + ... + m_{n}x_{n} + b
\end{equation}
\subsubsection{Método de Mínimos Cuadrados}
Para obtener los parámetros de la ecuación, usaremos el \textbf{método de mínimos cuadrados}, el cual se encarga de buscar la curva que mejor se ajusta a un conjunto de puntos minimizando la suma cuadrática de los residuos a los puntos de la curva\cite{WeissteinLeastFitting}.

Operando \cite{WeissteinLeastFitting}:
\begin{equation}
    ss_{xx} = \sum_{i=1}^{n}(x_{i}-\bar{x})^2
\end{equation}
\begin{equation}
        ss_{xy} = \sum_{i=1}^{n}(x_{i}-\bar{x})(y_{i}-\bar{y})
\end{equation}
De este modo, podemos estimar la \textit{pendiente} como:
\begin{equation}
    b = \frac{ss_{xy}}{ss_{xx}}
\end{equation}
Y la \textit{ordenada en el origen} en términos de b:
\begin{equation}
    a = \bar{y}-b\bar{x}
\end{equation}

\subsection{K-Nearest Neightbors}

Se trata de una de las formas más simples de aplicar un algoritmo de aprendizaje supervisado, con utilidad para tareas tanto de \textbf{regresión} como de \textbf{clasificación}.

Se considera un algoritmo \textit{no paramétrico} en tanto que no existen preconceptciones acerca de los datos subyacentes\cite{Belyadi2021SupervisedLearning}.

La base de su funcionamiento es la estimación de proximidad mediante el cálculo de \textbf{distancias}, en especial la \textbf{distancia euclídea}\cite{Greenacre2009CorrespondenceAnalysis}:
\begin{equation}
    d(p,q) = \sqrt{(p-q)^2}
\end{equation}

Podemos describir el algoritmo en los siguientes pasos\cite{Almomany2022OptimizedStudy}: 
\begin{enumerate}
    \item Determinar el número de vecinos más cercanos, conocido como el parámetro \textit{K}.
    \item Usar la función de \textbf{distancia} para calcular la distancia entre cada instancia del conjunto a predecir y todos los del entrenamiento.
    \item Ordena la distancia de menor a mayor y elige tantos elementos del conjunto de entrenamiento como K.
    \item Obtener la etiqueta o el valor numérico de los K-Vecinos.
    \item Devolver la \textit{media} (regresión) o la \textit{moda} (clasificación).
\end{enumerate}


\subsection{Árbol de Decisión}

Se trata de otro tipo de aprendizaje supervisado que, al igual que KNN, puede ser usado para ambos tipos de problema.

Actualmente, consiste un una de las herramientas \textbf{más usadas} para la toma de decisiones\cite{Navada2011OverviewLearning} en todo el mundo.

Para cumplir con esta tarea, se dibuja un árbol con diferentes \textit{ramas} y hojas, de forma que se incluyan \textit{todos los valores} de una situación particular\cite{Navada2011OverviewLearning}:

\imagen{Arbol de decisiones}{Ejemplo de Árbol de Decisiones}{.8}

Un árbol divide los datos en \textit{subárboles} de forma progresiva, desde la raíz, pasando por los nodos internos o de decisión y hasta llegar a los resultados, nodos hoja o \textbf{terminales}.

Existen varios algoritmos para la construcción de estos árboles, algunos de los más conocidos son ID3, C4.5, C5.0 y CART.  
De ellos, quizás el más famoso y del que derivan los demás, sea ID3, con un método de construcción \textbf{descendente y voraz} con atributos categóricos alcanzando la mayor \textit{ganancia de información}.

Conviene hacer referencia al método CART, cuya implementación optimizada por la librería \textit{scikit-learn} es la que hemos empleado en el proyecto. Este método es compatible con árboles de clasificación y regresión, aceptando tanto atributos como variables de decisión numéricas, creando árboles binarios con la mayor ganancia de información en cada nodo.\cite{Belyadi2021SupervisedLearning}

\subsubsection{Selección de Atributos}

Para elegir cuál de los N atributos del conjunto de datos debe ser colocado en cada uno de los nodos se establecen unos criterios de \textit{selección}.

Los más usados son:

\begin{enumerate}
    \item \textbf{Entropía}: Medida de la pureza e incertidumbre. Cuanto mayor sea, menor será su pureza. El cálculo es\cite{Belyadi2021SupervisedLearning}: \begin{equation}
        E(S) = \sum_{i=1}^{c}-P_{i}\log_{2}P_{i} 
    \end{equation}
    \item \textbf{Ganacia de Información}: Al construir un árbol, debemos seleccionar los atributos que alcancen la \textit{mayor} ganacia de información y menor entropía: \begin{equation}
        GI(Y,X) = E(Y) - E(Y,X)
    \end{equation}
    \item \textbf{Índice Gini}: Al contrario que la GI, este índice favorece la existencia de conjuntos de \textit{gran tamaño} y se calcula como la diferencia entre la unidad y la suma cuadrada de probabilidades para cada clase. \begin{equation}
        Gini = 1 - \sum_{i=1}^{c}(P_{i})^2
    \end{equation}
\end{enumerate}

Debemos tener en consideración que la implementación del paquete \textit{scikit-learn} toma como medida de selección \textit{predeterminada} el \textbf{índice Gini} \cite{Pedregosa2011Scikit-learn:Python}.


\subsection{Random Forest}

Este algoritmo permite la resolución tanto de problemas de clasificación como de regresión, siendo descrito por primera vez en: \cite{Ho1995RandomForests}, cuya \textbf{esencia} radica en la construcción de múltiples árboles dentro de un subespacio aleatorio del conjunto de variables de entrada.

Un modelo \textit{Random Forest} consiste en una colección de clasificadores con estructura \textit{en árbol}: 
\({h(x,\Theta_{k}), k = 1, ...}\)
Donde el conjunto de 
\(\Theta_{k}\) son vectores aleatorios independientes y con distribución \textbf{idéntica} y cada árbol emite un \textit{único voto} hacia la clase más popular de la entrada \textit{x}\cite{Breiman2001RandomForests}.

Aunque la definición previa hace referencia al modelo clásico, podemos hacer extrapolación hacia \textbf{árboles de regresión} y obtener predicciones en dicho ámbito \cite{Belyadi2021SupervisedLearning}.

\imagen{randomForest}{Ejemplo de Random Forest}{.8}

Algunos problemas recientes, como los \textbf{diagnósticos y procedimientos médicos}, tienen demasiadas variables de entrada, aunque cada una de ella tan sólo contiene una pequeña cantidad de información. En estos casos, un árbol de decisión o regresión único ofrecerá resultados tan sólo un poco mejores que la selección aleatoria. Sin embargo, la \textit{combinación} de árboles con un crecimiento usando características aleatorias puede \textbf{mejorar la precisión}\cite{Breiman2001RandomForests}.

Generalmente, existen \textbf{dos técnicas} para combinar varios árboles en uno solo\cite{Belyadi2021SupervisedLearning}:

\begin{enumerate}
    \item \textbf{Bagging}: En este método, propuesto por Leo Breiman\cite{Breiman1996BaggingPredictors}, se crean múltiples versiones de un predictor para alcanzar un único modelo agregado. Mediante el \textit{promedio} o la \textit{moda}, se produce la salida. Cada una de las versiones se forman realizando muestras aleatorias en tiempo de ejecución del conjunto de datos de entrenamiento y usándolas como un nuevo conjunto.
    \item \textbf{Boosting}: Al contrario que en la metodología anterior, los modelos son construidos de forma \textit{secuencial}, de manera similar al proceso de aprendizaje en el \textit{descenso de gradiente}, donde los pesos se centran en las instancias con predicciones incorrectas, buscando impulsar las predicciones de casos \textit{desafiantes}. Por tanto, las predicciones no provienen de una votación o promedio igualitario, sino \textit{ponderado}.
\end{enumerate}


\subsection{Redes Neuronales Artificiales}

Las \textbf{redes neuronales artificiales} son sistemas complejos basados en modelos matemáticos inspirados en la función, estructura y el procesamiento de la información del cerebro humano y el sistema nervioso central.\cite{Huang2022AutomaticNetworks}

De esta forma, una red es concebido como un sistema capaz de \textit{aprender} a predecir salidas tras realizar numerosas iteraciones.

Durante el proceso de aprendizaje, la salida de cada una de las neuronas será tomada como la entrada de la siguiente, tras pasar por una \textit{función umbral}. Para obtener la mejor \textit{precisión}, se aplica un algoritmo de entrenamiento con \textbf{propagación hacia detrás}.

Este proceso de aprendizaje se ha convertido en una valiosa herramienta para encontrar relaciones lineales y no lineales \textit{complejas}, de forma similar a una \textbf{caja negra}, y con múltiples aplicaciones en ingeniería, biología, matemáticas y medicina\cite{Moayedi2020AApplications}.

\subsubsection{Perceptrón}

El concepto de perceptrón fue derivado del modelo descrito por McCulloch y Pitts \cite{McCulloh1943ANets}, los cuales simularon los principios de las células nerviosas en un modelo matemática, comprobando que una única neurona es \textbf{capaz de realizar funciones lógicas}.

\begin{equation}
\sum w_{i}x_{i} \ge b
\end{equation}

Este modelo consiste en \textit{dos capas}. La primera, conocida como \textbf{capa de entrada}, recibe los estímulos y los transmite hacia la última capa, conocida como \textbf{capa de salida}. En ella, todos los estímulos de entrada son multiplicados por sus pesos respectivos y sumados junto al \textit{sesgo}. Finalmente, la función de activación es llamada con estos parámetros 

\imagen{perceptron.jpg}{Funcionamiento del Perceptrón. \cite{Huang2022AutomaticNetworks}}{.8}

\subsubsection{Perceptrón Multicapa}

Para una mejora en la resolución de \textit{problemas no lineales}, Hetch-Nielsen propuso una variante del perceptrón, añadiendo capas adicionales de neuronas entre la \textbf{entrada} y la \textbf{salida}\cite{Hecht-Nielsen1989Neurocomputing}.

\imagen{MLP.jpg}{Perceptrón Multicapa \cite{Huang2022AutomaticNetworks}}{.8}

En este modelo, diferenciamos dos componentes principales: \textit{neuronas} y \textit{conexiones}. Las neuronas serán las unidades de procesamiento, y cada conexión tendrá un peso y/o un sesgo correspondiente. Además, las capas ocultas tratarán de ser independientes del entorno, motivo por el cual reciben el nombre de \textit{capas ocultas}.

Al igual que en el perceptrón, el entrenamiento se realiza mediante un proceso de \textbf{retropropagación}, realizando correcciones a los pesos de los nodos para minimizar el error de la salida, dado por\cite{Haykin1998NeuralFoundation}:
\begin{equation}
    \varepsilon (n) = \frac{1}{2}\sum_{j}e_{j}^2(n)
\end{equation}
Y usando un \textbf{descenso de gradiente} obtenemos el cambio en cada peso\cite{Haykin1998NeuralFoundation}:

\begin{equation}
    \Delta w_{ji}(n) = -\eta \frac{\partial \varepsilon (n)}{\partial v_{j}(n)}y_{i}(n)
\end{equation}


\newpage

\section{Optimización en Planificación}

