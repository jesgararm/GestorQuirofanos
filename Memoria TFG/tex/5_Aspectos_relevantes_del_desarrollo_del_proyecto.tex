\capitulo{6}{Aspectos relevantes del desarrollo del proyecto}

\section{Obtención y Preprocesamiento de Datos}

\subsection{Fuente de Datos}

Se obtuvieron datos relativos a intervenciones quirúrgicas realizadas en el \textbf{Hospital Universitario Virgen del Rocío} de Sevilla, comprendidas entre las fechas \textit{1 de Enero de 2016} y \textit{1 de Noviembre de 2022}, con adecuada anonimización de los datos que garanticen su uso en el ámbito universitario.

Se obtuvieron datos relativos a las siguientes \textbf{especialidades quirúrgicas}:
\begin{enumerate}
    \item Cirugía Plástica y Reparadora.
    \item Cirugía Oral y Maxilofacial
    \item Neurocirugía.
    \item Cirugía General y del Aparato Digestivo.
    \item Cirugía Ortopédica y Traumatología.
    \item Otorrinolaringología.
    \item Cirugía Torácica
\end{enumerate}

\imagen{intervencionesEspecialidad}{Número de Intervenciones Registradas por Especialidad}{.9}

En total, se consideraron \textbf{25492 individuos} tras la realización de labores de adecuación e integración de las fuentes de datos.

 \imagen{tiposDatos}{Variables del Conjunto de Datos Base}{.9}
  \imagen{datosPlastica}{Variables del Conjunto de Datos Ampliado}{.9}

 \subsection{Preparación y Estadísticos}

 Tras obtener los \textbf{listados} de la Base de Datos anteriormente mencionada, se realizó una labor de \textit{adecuación} de los mismos a nuestro entorno de trabajo, \cite{McKinney2010DataPython}.

 \imagen{previaPreprocesado}{Aspecto de la Base de Datos antes de la edición.}{.9}

\imagen{postLimpieza}{Aspecto de los datos tras la limpieza y edición}{.9}

 Una vez obtuvimos nuestro dataset listo para la realización de labores de \textbf{minería}, procedimos a efectuar un \textit{análisis preliminar}, donde cabe destacar que la \textit{media} de duración de cada intervención \textbf{no varía} de forma estadísticamente significativa en función de la especialidad (\textit{ANOVA-Test}\footnote{Análisis de la varianza. Test estadístico realizado para valorar si existen diferencias significativas en las medias de los valores entre varios grupos}.)

 \imagen{duracionMedia}{Media de duraciones de intervenciones por Especialidad}{.9}

 Por otro lado, efectuamos un estudio de la \textbf{correlación} entre algunas de las variables registradas, centrándonos en los valores devueltos por el \textit{coeficiente de correlación de Spearman}\cite{Page1963OrderedRanks}. 
 Tras esta evaluación, encontramos que los valores referentes al \textbf{tipo, código de intervención y prioridad} son aquellos que, a priori, se encuentran más relacionados con la \textbf{duración}.

\imagen{correlacionSpearman}{Matriz de Correlación de Spearman}{.9}


 \subsection{Preprocesamiento de Datos}

 La mayor parte de los algoritmos de aprendizaje supervisado, especialmente aquellos que emplearemos en nuestro estudio, requieren contar con un conjunto de variables \textbf{numéricas} como conjunto de \textit{características}:
 
 \begin{enumerate}
     \item Para las variables \textbf{binarias}, se realizó una codificación a nivel de bit (0,1).
     \item Para las variables \textbf{ordinales}, se asignó una escala \textit{creciente} en función de la categoría.
     \item Para las variables \textbf{nominales}, usamos la técnica de \textit{One Hot Encoding}\footnote{Técnica que consiste en la división de una variable categórica en cada uno de sus posibles valores, realizando una asignación binaria en función del mismo a la instancia de entrenamiento.}, al tratarse de una de las técnicas más recomendadas para el manejo de variables categóricas en el entrenamiento de modelos de aprendizaje automático\cite{Potdar2017AClassifiers}.
 \end{enumerate}

 El seguimiento y proceso tanto de los procesos de \textbf{codificación} y \textbf{procesado}, así como de exportación posterior, se encuentra detallado en los Jupyter Notebooks: \textit{.\\Datos\\PreprocesadoDatos.ipynb} y \textit{.\\Datos\\codificacionDatos.ipynb}.

Por último, de entre todas las estrategias\cite{Emmanuel2021ALearning} existentes para lidiar con los valores \textbf{ausentes} durante la fase de procesamiento, optamos por la \textbf{eliminación} de instancias, dado que el carácter arbitrario de las labores de codificación y la \textit{escasez} de variables correladas dificultan la aplicación de métodos basados en \textit{sustitución o interpolación}. 

\newpage

\section{Aprendizaje Supervisado}

En este apartado se describe el procedimiento de exploración, análisis e implementación de diferentes modelos predictivos, basados en el paradigma de \textit{aprendizaje supervisado} con el objetivo de obtener la predicción más \textbf{fidedigna} posible, de forma que pudiese ser empleada como entrada del modelo de optimización posterior.


\subsection{Regresión Lineal}

Comenzamos aplicando un modelo simple de \textbf{regresión múltiple}, siguiendo las bases teóricas especificadas en apartados anteriores y basándonos en la implementación de la librería \textit{scikit-learn}\cite{2021Scikit-LearnPython}.

Para el ajuste de los hiperparámetros, empleamos un modelo de validación cruzada de tipo \textit{GridSearch}\footnote{Técnica de validación cruzada incluida en scikit-learn, consistente en extraer los mejores valores y combinaciones introducidos en la cuadrícula de parámetros.}.

Tras su ejecución con el \textbf{dataset principal}, calculamos las métricas de error, mostrando unos valores \textit{desproporcionados}, en torno a miles de minutos de error medio, muy diferentes de los 50-80 de RMSE otorgados por otros estudios\cite{ShahabiKargar2014PredictingSurgery}.

\tablaSmall{Errores en Modelo de Regresión Lineal}{c|c|c}{metRegLin}{\textbf{Métricas} & \textbf{Pre-Outliers} & \textbf{Post-Outliers}\\}{
MSE & 55694590.09 & 3461.42\\
RMSE & 7462.88 & 58.33\\
R2 & 0.000000078 & 0.20\\
}

Esta situación nos hizo sospechar de la presencia de numerosos \textit{outliers} en nuestro conjunto de datos inicial. Por tanto, reajustamos nuestro modelo, haciendo uso del IQR\cite{Bonthu2021DetectingOutliers}, seleccionando aquellas instancias de entrenamiento con duración comprendida entre 1.5 veces por debajo y por encima de los cuartiles primero y tercero, respectivamente.

Como podemos comprobar, la ejecución muestra unos valores mucho más coherentes y concordantes de la literatura, constituyendo un buen punto de partida para nuestro ensayo.

\imagen{scatterLinearReg}{Conjunto de Validación en Regresión Lineal}{.9}

De forma paralela, entrenamos el modelo con el dataset \textbf{ampliado}, disminuyendo el RMSE un 20\% e incrementando un 50\% el índice $R^{2}$.

Tras el entrenamiento, se exportan ambos modelos para su explotación posterior.


\subsection{Árbol de Regresión}

Tras la ejecución del modelo lineal, pasamos a explorar el rendimiento de los árboles de regresión.
De nuevo, los hiperparámetros se optimizaron con el método de validación cruzada en malla y se manejaron los valores límites haciendo uso del rango intercuartílico.

Así, tras su ejecución, obtuvimos una \textbf{reducción de la raíz del error cuadrático medio} ligeramente superior al 20\%. No obstante, las métricas relativas a su explotación en el conjunto ampliado no ofrecieron mejoras superiores al 10\%.

\imagen{ejemploRegressionTree}{Sección del Árbol de Regresión Construido}{.9}


\subsection{K-Nearest Neightbors}

Probamos con uno de los algoritmos de aprendizaje supervisado más simples, el cual, pese a ser usado mayoritariamente en problemas de clasificación, puede ser empleado para regresión empleando la \textit{media} en lugar de la \textit{moda} de los K vecinos más cercanos.

Los hiperparámetros, en especial el valor de K o el tipo de distancia (\textit{en nuestra implementación, los mejores valores encontrados fueron la distancia de Manhattan\footnote{\(\sum_{i=1}^{n} |p_{i} - q_{i}|\)} y K= 14}).

Sin embargo, las métricas de error son \textit{similares} a las otorgadas por el algoritmo de regresión lineal, con un tiempo de ejecución \textbf{sustancialmente mayor}.

\imagen{KNNPerf}{Rendimiento del modelo KNN}{.8}







 